
"Advertising is only evil when it advertises evil things."

So said the legendary David Ogilvy many years ago.

But that was before the advent of computers, the Internet and all things digital.

The subcommittee highlighted a December 2013 incident in which an Internet user visited a mainstream website and had all of her personal information stolen via an ad on Yahoo's network. Even worse: She didn't have to click on it to deliver a virus that gobbled up her information. And as many as 2 million others may have been exposed to the attack.

Bottom line: In our world, advertising can be evil when it does evil things.

And in a world where we need to feed the insatiable maw of Big Data, where interactivity is the price of entry, where ever-better targeting drives astronomical evaluations, where the fear of being left out opens us up in vulnerable ways... In a world where privacy and confidentiality and security often get in each other's way -- not to our benefit, in my mind -- as I see it, privacy is a question of what you share or choose not to share about yourself. Confidentiality is a pact between you and another party that is clearly restrictive and security is your right to protection.

If you choose to share your information with Google, so be it -- if you don't mind them sharing with others, so be it -- but they still have the obligation to protect your data in their system and at your source from others who are not part of the pact.

In such a world I'd say we have an issue.

I say that because even a cursory examination of the current litigation landscape points to the well-known axiom (albeit paraphrased and cleaned up here): "Waste runs downhill."

The effect of which will be that while the regulatory regulators might start with the ad networks, everyone will soon start pushing indemnity to the next level down in the chain, and soon advertisers and agencies will be afraid to place interactive ads, to collect data, or use the full power of the digital universe for our benefit.

The great Lester Wunderman -- an early data pioneer and predictor of digital interactivity long before computers became personal -- has pointed out that consumers would sleep better if they knew that even in the world of Big Data much of what is collected and touted is actually useless. And therein, in my view, is the heart of the matter.

Because we gobble up so much data, because we are free with so much data, we are being seduced by visions of huge payouts and not by the true potential of how it might really change our lives.

Ergo, we leave ourselves open for malicious attacks because no one wants to limit their own ability to legally, and hopefully with some accountability, get what the bad guys are stealing.

Seems to me that we need to act immediately -- that is, the industry and consumers in tandem for a change. Because at the end of the day we really do share a common outcome, and that is a system that works, provides services,is efficient and effective, and saves and makes money. In other words, something for all.

As an industry we need to kill the digibabble and begin to limit the data we collect/demand and spend more time understanding what we have and how to use it.

Consumers need to demand more accountability, but with the filter of "give me more, not less" -- as less only plays into the hands of those who want to limit.

"Advertising reflects the mores of society, but it does not influence them."

Maybe that is true of the ads themselves but given the power of the industry today, in that monetization of just about everything new and digital has an advertising component, perhaps it's time that we actually take the lead in influencing -- the lead in changing, the lead in helping our new world better utilize the amazing tools we have to change it all for the better, instead of worrying about the worst.

Get top stories and blog posts emailed to me each day..

Use this form to alert a HuffPost editor about a factual or typographical error in this story.

Thank you!
