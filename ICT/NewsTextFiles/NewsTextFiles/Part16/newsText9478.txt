
The pressure to publish original research can mean scientists are neglecting to verify the work of others. In its current issue, the journal Social Psychology is trying a different approach.

Copyright © 2014 NPR. For personal, noncommercial use only. See Terms of Use. For other uses, prior permission required.

Next we're going to report on scientific research, in particular on the way that reporting on scientific research might actually warp the findings. Scientists face pressure to publish new discoveries, which in turn might influence what they study, and that, of course, is not necessarily a good thing. There's work being published today that's part of an effort to fix this problem. NPR's Shankar Vendantam joined our colleague, Steve Inskeep, to talk about it.

Shankar, welcome back.

SHANKAR VEDANTAM, BYLINE: Good morning, Steve.

VEDANTAM: Well, the problem is that the incentives in science today are all about breaking new ground, and there's much less incentive to making sure that the ground you're standing on is actually solid. Most people think about science as being about breakthroughs, but science really is about the gradual accumulation of knowledge and retesting what we think we know.

I spoke with psychologist Brian Nosek of the University of Virginia. He's been working on this issue for a while.

BRIAN NOSEK: The issues are pervasive in every science. Scientists are rewarded for publication over accuracy. There isn't a culture of replication across most disciplines. We're not rewarded for redoing what someone else does. The main reward is for doing something novel.

INSKEEP: Rewarded for publications over accuracy. I guess we should explain that scientific findings are published in prestigious journals and it's a big deal when your findings are published there.

VEDANTAM: It can make or break your career, and so especially if you're a young researcher the pressure to come up with a publication is extraordinary. Now, Nosek is the editor of a journal called Social Psychology and this is a field where some recent results have been called into question. And the way that journals typically work is the scientist does a study, writes it up, sends it to the journal, journal sends out the study to peer reviewers who review the study.

And if they give the okay, the journal considers it for publication. Nosek thinks this model creates perverse incentives, because if a study confirms an older result, the journals tend to say, well, we knew that already, it's not a novel finding and they're less inclined to publish it. Now, if the replication contradicts an earlier finding, where the journal sends out the study to the peer reviewers, some of the peer reviewers might have been the researchers who conducted the original study and they can now find ways to shoot down the study and reject the study and say we shouldn't be publishing it anyway.

And so what this does is it creates a disincentive for researchers to conduct replications at all.

INSKEEP: And this is how you're supposed to figure out that science is true, by doing the experiment again and again and again.

VEDANTAM: That's exactly right. So in this current issue of the journal Social Psychology, Nosek turns this model on its head. Every article that's in the journal is focused on replicating an earlier study. And as a second innovation, all the replications were accepted for publication before they were conducted, so the peer reviewers only looked at the methodology of the study and if the science were solid, the study was guaranteed publication.

Nosek thinks that this creates the incentives to do the best science, not just come up with the sexiest result.

VEDANTAM: They found lots of things that are interesting, Steve, but let me give you one specific example. In 1999, the researchers Margaret Shea(ph), Todd Patinski(ph)  and Alini Ambadi (ph) came up with a classic experiment. They were looking at how stereotypes affect how people behave. Not the people who hold the stereotypes, but the people who are affected by the stereotype. This study was looking at how Asian women perform in math tests.

There's a common stereotype that Asians are good at math and there's also a common stereotype that women are not good at math. When the researchers reminded the volunteers of either their Asian or their female identity, distinct differences in performance emerged. Here's Nosek again.

NOSEK: Asian women who were reminded that they were Asian performed better on the math test. Whereas Asian women reminded that they were women performed worse on the same math test. Something that seems like it shouldn't be flexible, how well we perform in math, is flexible as a function of the identities that we have in mind and stereotypes associated with those identities.

VEDANTAM: Well, that's exactly right. Alice Moon(ph) and Scott Reader(ph) at UC Berkley re-did the study in Northern California and they found the effect did not hold. Now, our first reaction is to say, look, the original study was debunked, but it turns out the answer is actually more complicated than that because there was a second replication. At Georgia Southern University, Carolyn Gibson(ph), Joy Losi(ph), and Christine Vitiello(ph) confirmed the original study.

And now we are forced to be curious rather than judgmental.

INSKEEP: I guess this is a reminder that you need to keep an open mind and how subtly you can close your mind without realizing it.

VEDANTAM: And in many ways, Steve, that's the point of science, to recognize that beneath what we think we know there are layers and nuances that are waiting to be discovered.

INSKEEP: Shankar, thanks very much.

VEDANTAM: Thank you, Steve.

INSKEEP: That's NPR's Shankar Vendantam. You can follow him as always on Twitter at HiddenBrain. You can follow this program @MorningEdition and @NPRInskeep as well as @NPRGreene.

Copyright © 2014 NPR. All rights reserved. No quotes from the materials contained herein may be used in any media without attribution to NPR. This transcript is provided for personal, noncommercial use only, pursuant to our Terms of Use. Any other use requires NPR's prior permission. Visit our permissions page for further information.

NPR transcripts are created on a rush deadline by a contractor for NPR, and accuracy and availability may vary. This text may not be in its final form and may be updated or revised in the future. Please be aware that the authoritative record of NPR's programming is the audio.

Please keep your community civil. All comments must follow the NPR.org Community rules and terms of use , and will be moderated prior to posting. NPR reserves the right to use the comments we receive, in whole or in part, and to use the commenter's name and location, in any medium. See also the Terms of Use , Privacy Policy and Community FAQ .
